---
title: "A re-analysis of the CaHMP-ED experiment using spectral network regression"
author: "Alex Hayes"
format: html
editor_options: 
  chunk_output_type: console
---

## Brief summary of experiment

During the COVID-19 pandemic, we randomly assigned 662 participants (around 88% female, 90% White, m age=42.6) to a four-week smartphone-based MBI or to wait-list control. Each week until post-test and a sixth time at three-month follow-up, we assessed psychological distress (aggregate of Perceived Stress Scale, PROMIS Anxiety and Depression scales) and four preregistered mediators (Five Facet Mindfulness Questionnaire mindful action subscale, NIH Toolbox Loneliness, Drexel Defusion Scale, and Meaning in Life Questionnaire presence subscale). Using latent growth structural equation mediation models, we tested preregistered hypotheses about intervention effects on mediators and mediator effects on follow-up distress. 

Some codebook notes:

- `redcap_event_name` = time point, scr = screening, pre = baseline, w1-w3 = week 1 to week 3, post = post-test, 3mo = 3-month follow-up
- `nih_lonliness_q01-q05` = NIH Toolbox Loneliness items
- `mlq10_q01-q10` = Meaning in Life Questionnaire. We focused on the "presence" subscale which includes items 1, 4, 5, 6, and 9 (reverse scored).
- `ffmq_8_q01_q08` = Five Facet Mindfulness Questionnaire Acting with Awareness subscale
- `promis_eddep` = PROMIS Depression computer adaptive version
- `promis_edanx` = PROMIS Anxiety computer adaptive version
- `nih_perstr_q01` = NIH Toolbox Perceived Stress Scale (items 4, 5, 7, and 8 are reverse scored)
- `dds_10_q01-q10` = Drexel Defusion Scale

The primary outcome in the trial was a composite of Perceived Stress, PROMIS Depression, and PROMIS Anxiety. Both PROMIS measures were computer adaptive, so I'm not sure how you all want to handle that for item-level analyses. Our candidate mediators were the remaining measures (FFMQ Awareness, NIH Toolbox Loneliness, Drexel Defusion Scale, Meaning in Life Questionnaire Presence subscale).

- don't include stress as a mediator, it's an outcome.


### ATE

```{r}
library(halfmoon)

raw |> 
  ggplot() +
  aes(promis_bank_v10_depression_tscore, fill = meta_oa_info_group) +
  geom_mirror_histogram() +
  facet_wrap(vars(redcap_event_name))

raw |> 
  ggplot() +
  aes(promis_bank_v10_anxiety_tscore, fill = meta_oa_info_group) +
  geom_mirror_histogram() +
  facet_wrap(vars(redcap_event_name))

data |> 
  nest(data = -c(redcap_event_name)) |> 
  mutate(
    ols_fit = map(data, \(df) lm(promis_eddep ~ condition, data = df)),
    tidied = map(ols_fit, broom::tidy, conf.int = TRUE)
  ) |> 
  select(redcap_event_name, tidied) |> 
  unnest(c(tidied)) |> 
  mutate(
    event = forcats::fct_inorder(redcap_event_name)
  ) |> 
  filter(str_detect(term, "condition")) |> 
  ggplot() +
  aes(
    x = event,
    ymin = conf.low,
    y = estimate,
    ymax = conf.high,
    group = 1
  ) +
  geom_point() +
  geom_line() +
  geom_ribbon(alpha = 0.1)

```



## Plotting individual level trajectories over time

```{r}
data |>
  select(id, condition, redcap_event_name, since_baseline, time, contains("nih_lonliness_")) |> 
  pivot_longer(
    contains("nih_lonliness_"),
    names_to = "item",
    names_prefix = "nih_lonliness_",
    values_to = "response"
  ) |> 
  ggplot(aes(since_baseline, response, group = id, color = condition)) +
  geom_line(alpha = 0.1) +
  geom_point(alpha = 0.1) +
  facet_grid(rows = vars(item))
```

```{r}
data |>
  select(id, condition, redcap_event_name, since_baseline, time, contains("mlq_10_")) |> 
  pivot_longer(
    contains("mlq_10_"),
    names_to = "item",
    names_prefix = "mlq_10_",
    values_to = "response"
  ) |> 
  ggplot(aes(since_baseline, response, group = id, color = condition)) +
  geom_line(alpha = 0.1) +
  geom_point(alpha = 0.1) +
  facet_grid(rows = vars(item))
```

# Factor analysis at each time point

```{r}
nested_by_event <- data |> 
  select(-id, -since_baseline, -time, -condition, -contains("promis")) |> 
  na.omit() |> 
  nest(data = -redcap_event_name) |> 
  mutate(
    dense = map(data, as.matrix),
    A = map(dense, as, "sparseMatrix")
  )

nested_by_event
```

```{r}
library(vsp)
library(gdim)
library(latentnetmediate)

A1 <- nested_by_event$A[[1]]

eigcv <- eigcv(as(A1, "sparseMatrix"), k_max = 20, laplacian = FALSE, regularize = FALSE)
plot(eigcv)
eigcv

fa <- vsp(A1, rank = 3)
fa

plot_ipr_pairs(fa)

plot_mixing_matrix(fa)

screeplot(fa)

plot_varimax_y_pairs(fa, 1:3) # item space
plot_varimax_z_pairs(fa, 1:3) # person space

fa |> 
  get_varimax_y() |> 
  set_names(nm = c("item", paste0("Y", 1:3))) |> 
  pivot_longer(
    contains("Y")
  ) |> 
  ggplot(aes(name, item, fill = value)) +
  geom_raster() +
  scale_fill_gradient2() +
  theme(
    axis.title.y = element_blank()
  ) +
  labs(
    x = "Latent factor",
    caption = "We find two, at most three, latent factors",
    title = "Latent factors at pre-screen"
  )

Xhat <- VS(A1, rank = 3)

fa |> 
  get_svd_v() |> 
  set_names(nm = c("item", paste0("V", 1:3))) |> 
  pivot_longer(
    contains("V")
  ) |> 
  ggplot(aes(name, item, fill = value)) +
  geom_raster() +
  scale_fill_gradient2() +
  theme(
    axis.title.y = element_blank()
  ) +
  labs(
    x = "Latent factor",
    caption = "We find two, at most three, latent factors",
    title = "Latent factors at pre-screen"
  )

pairs(Xhat)

```

Now in practice we should probably jointly embed all of the networks, so that they share the same latent space.

```{r}
A2 <- nested_by_event$A[[2]]

eigcv <- eigcv(as(A2, "sparseMatrix"), k_max = 20, laplacian = FALSE, regularize = FALSE)
plot(eigcv)
eigcv

fa <- vsp(A2, rank = 3)
fa

plot_ipr_pairs(fa)

plot_mixing_matrix(fa)

screeplot(fa)

plot_varimax_y_pairs(fa, 1:3) # item space
plot_varimax_z_pairs(fa, 1:3) # person space

fa |> 
  get_varimax_y() |> 
  set_names(nm = c("item", paste0("Y", 1:3))) |> 
  pivot_longer(
    contains("Y")
  ) |> 
  ggplot(aes(name, item, fill = value)) +
  geom_raster() +
  scale_fill_gradient2() +
  theme(
    axis.title.y = element_blank()
  ) +
  labs(
    x = "Latent factor",
    caption = "We find two, at most three, latent factors",
    title = "Latent factors at pre-screen"
  )
```

```{r}
A3 <- nested_by_event$A[[3]]

eigcv <- eigcv(
  A = as(A3, "sparseMatrix"), 
  k_max = 20, 
  laplacian = FALSE, 
  regularize = FALSE,
  method = "BH"
)
plot(eigcv)
eigcv

fa <- vsp(A3, rank = 3)
fa

plot_ipr_pairs(fa)

plot_mixing_matrix(fa)

screeplot(fa)

plot_varimax_y_pairs(fa, 1:3) # item space
plot_varimax_z_pairs(fa, 1:3) # person space

fa |> 
  get_varimax_y() |> 
  set_names(nm = c("item", paste0("Y", 1:3))) |> 
  pivot_longer(
    contains("Y")
  ) |> 
  ggplot(aes(name, item, fill = value)) +
  geom_raster() +
  scale_fill_gradient2() +
  theme(
    axis.title.y = element_blank()
  ) +
  labs(
    x = "Latent factor",
    caption = "We find two, at most three, latent factors",
    title = "Latent factors at pre-screen"
  )
```

```{r}
A4 <- nested_by_event$A[[4]]

eigcv <- eigcv(
  A = as(A4, "sparseMatrix"), 
  k_max = 20, 
  laplacian = FALSE, 
  regularize = FALSE,
  method = "BH"
)
  
plot(eigcv)
eigcv

fa <- vsp(A4, rank = 2, degree_normalize = FALSE)
fa

plot_ipr_pairs(fa)

# use to estimate portion of variance explained by PCs if desired
fit <- irlba::prcomp_irlba(A4, n = 20)
fit

summary(fit)

plot_mixing_matrix(fa)

screeplot(fa)

plot_varimax_y_pairs(fa) # item space
plot_varimax_z_pairs(fa) # person space

nested_by_event$data[[4]]

fa |> 
  get_varimax_z() |> 
  
  %>% GGally::ggpairs(ggplot2::aes(alpha = 0.001, color = intervention)) + ggplot2::theme_minimal()

fa |> 
  get_varimax_y() |> 
  set_names(nm = c("item", paste0("Y", 1:fa$rank))) |> 
  pivot_longer(
    contains("Y")
  ) |> 
  ggplot(aes(name, item, fill = value)) +
  geom_raster() +
  scale_fill_gradient2() +
  theme(
    axis.title.y = element_blank()
  ) +
  labs(
    x = "Latent factor",
    caption = "We find two, at most three, latent factors",
    title = "Latent factors at pre-screen"
  )

fa |> 
  get_svd_v() |> 
  set_names(nm = c("item", paste0("Y", 1:fa$rank))) |> 
  pivot_longer(
    contains("Y")
  ) |> 
  ggplot(aes(name, item, fill = value)) +
  geom_raster() +
  scale_fill_gradient2() +
  theme(
    axis.title.y = element_blank()
  ) +
  labs(
    x = "Latent factor",
    caption = "We find two, at most three, latent factors",
    title = "Latent factors at pre-screen"
  )


```

```{r}
A5 <- nested_by_event$A[[5]]

eigcv <- eigcv(as(A5, "sparseMatrix"), k_max = 20, laplacian = FALSE, regularize = FALSE)
plot(eigcv)
eigcv

fa <- vsp(A5, rank = 3)
fa

plot_ipr_pairs(fa)

plot_mixing_matrix(fa)

screeplot(fa)

plot_varimax_y_pairs(fa, 1:3) # item space
plot_varimax_z_pairs(fa, 1:3) # person space

fa |> 
  get_varimax_y() |> 
  set_names(nm = c("item", paste0("Y", 1:3))) |> 
  pivot_longer(
    contains("Y")
  ) |> 
  ggplot(aes(name, item, fill = value)) +
  geom_raster() +
  scale_fill_gradient2() +
  theme(
    axis.title.y = element_blank()
  ) +
  labs(
    x = "Latent factor",
    caption = "We find two, at most three, latent factors",
    title = "Latent factors at pre-screen"
  )
```

```{r}
A6 <- nested_by_event$A[[6]]

eigcv <- eigcv(as(A6, "sparseMatrix"), k_max = 20, laplacian = FALSE, regularize = FALSE)
plot(eigcv)
eigcv

fa <- vsp(A6, rank = 3)
fa

plot_ipr_pairs(fa)

plot_mixing_matrix(fa)

screeplot(fa)

plot_varimax_y_pairs(fa, 1:3) # item space
plot_varimax_z_pairs(fa, 1:3) # person space

fa |> 
  get_varimax_y() |> 
  set_names(nm = c("item", paste0("Y", 1:3))) |> 
  pivot_longer(
    contains("Y")
  ) |> 
  ggplot(aes(name, item, fill = value)) +
  geom_raster() +
  scale_fill_gradient2() +
  theme(
    axis.title.y = element_blank()
  ) +
  labs(
    x = "Latent factor",
    caption = "We find two, at most three, latent factors",
    title = "Latent factors at pre-screen"
  )
```

```{r}
nested_by_event |> 
  mutate(
    fa = map(A, vsp, rank = 3),
    X = map(A, latentnetmediate::US, rank = 3)
  )
```



```{r}
library(latentnetmediate)
library(tidygraph)

cross_section_to_tbl_graph <- function(df) {
  A <- df |> 
    select(-id, -since_baseline, -time, -condition, -contains("promis")) |> 
    na.omit() |> 
    as.matrix() |> 
    as("sparseMatrix")
  
  rownames(A) <- df$id
  
  node_data <- df |> 
    select(id, since_baseline, time, condition, contains("promis")) |> 
    mutate(
      name = as.character(id)
    ) |> 
    select(-id)
  
  igraph::graph_from_incidence_matrix(A, weighted = TRUE) |> 
    as_tbl_graph() |> 
    left_join(
      node_data, by = "name"
    )
}

nested <- data |> 
  na.omit() |> 
  nest(data = -redcap_event_name) |> 
  mutate(
    tbl_graph = map(data, cross_section_to_tbl_graph),
    meddep = map(tbl_graph, netmediate, promis_eddep ~ condition, rank = 2),
    medanx = map(tbl_graph, netmediate, promis_edanx ~ condition, rank = 2)
  ) |> 
  select(-data)

levels <- c(
  "pre_arm_1",
  "w1_arm_1",
  "w2_arm_1",
  "w3_arm_1",
  "post_arm_1",
  "3mo_arm_1"
)

##### SCRATCH -- visualizing result of intervention

library(broom)

tbl_graph <- nested$tbl_graph[[4]] |> 
  arrange(condition)

lnm <- netmediate(tbl_graph, promis_eddep ~ condition, rank = 2, coembedding = "Z")

lnm$mediator_model

tbl_graph |> 
  filter(!type) |> 
  as_tibble() |> 
  lm(promis_eddep ~ condition, data = _) |> 
  summary()

anova(lnm$outcome_model)

# NOTE: being sloppy about overloading
A4 <- tbl_graph |> 
  igraph::as_biadjacency_matrix(attr = "weight")

Uhat <- US(A4, rank = 2)
Vhat <- VS(A4, rank = 2)

tbl_graph |> 
  filter(!type) |> 
  as_tibble() |> 
  lm(promis_eddep ~ condition + Uhat, data = _) |> 
  anova()

A4 |> 
  as_tibble(rownames = "name") |> 
  pivot_longer(
    -name,
    names_to = "item",
    values_to = "response"
  ) |> 
  ggplot(aes(name, item, fill = as.factor(response))) +
  geom_raster() +
  scale_fill_viridis_d()

Ahat <- tcrossprod(Uhat, Vhat)


dimnames(Ahat) <- dimnames(A4)

Ahat |> 
  as_tibble(rownames = "name") |> 
  pivot_longer(
    -name,
    names_to = "item",
    values_to = "response"
  ) |> 
  ggplot(aes(name, item, fill = response)) +
  geom_raster() +
  scale_fill_viridis_c()

norm(A4)
norm(A4 - Ahat)


o_fit <- nested$meddep[[4]]$outcome_model
m_fit <- nested$meddep[[4]]$mediator_model
m_fit

mf <- model.frame(m_fit)
mf$W[, 2] <- 0
mf

Uhat0 <- predict(m_fit, mf)

Ahat0 <- tcrossprod(Uhat0, Vhat)
dimnames(Ahat0) <- dimnames(A4)

Ahat0 |> 
  as_tibble(rownames = "name") |> 
  pivot_longer(
    -name,
    names_to = "item",
    values_to = "response"
  ) |> 
  ggplot(aes(name, item, fill = response)) +
  geom_raster() +
  scale_fill_viridis_c()


diff <- Ahat - Ahat0 

diff |> 
  as_tibble(rownames = "name") |> 
  sample_n(10) |> 
  pivot_longer(
    -name,
    names_to = "item",
    values_to = "response"
  ) |> 
  ggplot(aes(name, item, fill = response)) +
  geom_raster() +
  scale_fill_gradient2()

predict(m_fit) - predict(m_fit, mf)
# post intervention visualization

predict(m_fit)


##### END SCRATCH -- visualizing result of intervention

unnested <- nested |> 
  mutate(
    table = map(meddep, pluck, "effects"),
    event = factor(redcap_event_name, levels = levels)
  ) |> 
  select(-tbl_graph, -meddep) |> 
  unnest(table)

unnested |> 
  ggplot(
    aes(
      x = event,
      ymin = conf.low,
      y = estimate,
      ymax = conf.high,
      color = estimand,
      group = estimand,
      fill = estimand
    )
  ) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_line(size = 1) +
  # geom_pointrange(position = position_dodge(width = 0.5)) +
  geom_ribbon(alpha = 0.3) +
  scale_color_brewer(type = "qual") +
  scale_fill_brewer(type = "qual") +
  theme(
    # axis.text.x = element_text(angle = 90),
    axis.title.x = element_blank()
  ) +
  labs(
    title = "Direct and indirect effects of treatment on depression t-score over time",
    x = "Time-point in study",
    y = "Estimated effect on depression tscore",
    subtitle = "Presented with 95% pointwise confidence intervals"
  )

ggsave(
  "~/Desktop/depression.png",
  dpi = 600,
  width = 16,
  height = 9
)


nested |> 
  mutate(
    table = map(medanx, pluck, "effects"),
    event = factor(redcap_event_name, levels = levels)
  ) |> 
  select(-tbl_graph, -medanx) |> 
  unnest(table) |> 
  ggplot(
    aes(
      x = event,
      ymin = conf.low,
      y = estimate,
      ymax = conf.high,
      color = estimand,
      group = estimand,
      fill = estimand
    )
  ) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_line(size = 1) +
  # geom_pointrange(position = position_dodge(width = 0.5)) +
  geom_ribbon(alpha = 0.3) +
  scale_color_brewer(type = "qual") +
  scale_fill_brewer(type = "qual") +
  theme(
    # axis.text.x = element_text(angle = 90),
    axis.title.x = element_blank()
  ) +
  labs(
    title = "Direct and indirect effects of treatment on anxiety t-score over time",
    x = "Time-point in study",
    y = "Estimated effect on anxiety tscore",
    subtitle = "Presented with 95% pointwise confidence intervals"
  )


```

TODO: ask about controlling for possible confounders, and also about controlling for the baseline effect

```{r}
data |> 
  select(redcap_event_name, contains("promis")) |> 
  pivot_longer(
    contains("promis")
  ) |> 
  ggplot(aes(value, fill = name)) +
  geom_histogram() +
  facet_grid(
    rows = vars(name),
    cols = vars(redcap_event_name)
  )
```


